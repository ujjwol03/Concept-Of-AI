{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Ensemble Methods and Hyperparameter Tuning."],"metadata":{"id":"kewmx_J7JMUl"}},{"cell_type":"markdown","source":["**1. Implement Classification Models:**\n","\n","• Train a Decision Tree Classifier and a Random Forest Classifier using scikit-learn.\n","\n","• Compare the models based on their F1 scores."],"metadata":{"id":"i0vBV-ofJUZb"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","\n","wine = load_wine()\n","X, y = wine.data, wine.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"z-WIsOhpLThh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import f1_score\n","\n","dt_classifier = DecisionTreeClassifier(random_state=42)\n","dt_classifier.fit(X_train, y_train)\n","y_pred_dt = dt_classifier.predict(X_test)\n","f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n","print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5viqSnYLixL","outputId":"3c01c2f4-77a3-4cf7-e1d6-37b12626c84e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree F1 Score: 0.9440\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf_classifier = RandomForestClassifier(random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","y_pred_rf = rf_classifier.predict(X_test)\n","f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n","print(f\"Random Forest F1 Score: {f1_rf:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l7AU0nYGLrQl","outputId":"a2ca46b3-945f-48df-c1a8-7e05bec80505"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest F1 Score: 1.0000\n"]}]},{"cell_type":"markdown","source":["**2. Hyperparameter Tuning:**\n","\n","• Identify three hyperparameters of the Random Forest Classifier.\n","\n","• Perform hyperparameter tuning using GridSearchCV to optimize these parameters.\n","\n","• Take hints from the scikit-learn documentation to guide the implementation."],"metadata":{"id":"hQFH9G7HJY4r"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 5, 10],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='f1_weighted')\n","grid_search.fit(X_train, y_train)\n","\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(\"Best F1 Score:\", grid_search.best_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LHdUl6ydLz3f","outputId":"d5d5fb06-25b1-42fd-d900-3a7166efd3fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n","Best F1 Score: 0.9782952128219708\n"]}]},{"cell_type":"markdown","source":["**3. Implement Regression Model:**\n","\n","• Train a Decision Tree Regressor and a Random Forest Regressor using scikit-learn.\n","\n","• Identify three parameters for Random Forest Regressio and Perform hyperparameter tuning using\n","RandomSearchCV to optimize these parameters."],"metadata":{"id":"4WEkvJZMJcq5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QOErozLI5mf","outputId":"6fab702f-23fd-405c-ff79-27ae26da07f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Regressor MSE: 0.1667\n","Random Forest Regressor MSE: 0.0648\n","Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 30}\n","Best MSE: 0.0468\n"]}],"source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import mean_squared_error\n","\n","#Train a Decision Tree Regressor\n","dt_regressor = DecisionTreeRegressor(random_state=42)\n","dt_regressor.fit(X_train, y_train)\n","y_pred_dt_reg = dt_regressor.predict(X_test)\n","mse_dt_reg = mean_squared_error(y_test, y_pred_dt_reg)\n","\n","#Train a Random Forest Regressor\n","rf_regressor = RandomForestRegressor(random_state=42)\n","rf_regressor.fit(X_train, y_train)\n","y_pred_rf_reg = rf_regressor.predict(X_test)\n","mse_rf_reg = mean_squared_error(y_test, y_pred_rf_reg)\n","\n","print(f\"Decision Tree Regressor MSE: {mse_dt_reg:.4f}\")\n","print(f\"Random Forest Regressor MSE: {mse_rf_reg:.4f}\")\n","\n","#Define the hyperparameters to tune for Random Forest Regressor\n","param_dist = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","#Perform RandomizedSearchCV to find the best hyperparameters\n","random_search = RandomizedSearchCV(estimator=rf_regressor, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n","random_search.fit(X_train, y_train)\n","\n","print(f\"Best Hyperparameters: {random_search.best_params_}\")\n","print(f\"Best MSE: {-random_search.best_score_:.4f}\")"]}]}